target:
  type: spark
  host: "{{ env_var('DBT_DATABRICKS_HOST_NAME') }}"
  cluster: "{{ env_var('DBT_DATABRICKS_CLUSTER_NAME') }}"
  token: "{{ env_var('DBT_DATABRICKS_TOKEN') }}"
  method: odbc
  driver: /Library/simba/spark/lib/libsparkodbc_sbu.dylib
  port: 443
  schema: "analytics_{{ var('_dbt_random_suffix') }}"
  connect_retries: 5
  connect_timeout: 60
projects:
  - overrides: incremental
    paths:
      "models/incremental.sql":
        materialized: incremental
        body: "select * from {{ source('raw', 'seed') }}"
    facts:
      base:
        rowcount: 10
      extended:
        rowcount: 20
  - overrides: snapshot_strategy_check_cols
    dbt_project_yml: &file_format_delta
      # we're going to UPDATE the seed tables as part of testing, so we must make them delta format
      seeds:
        dbt_test_project:
          file_format: delta
      snapshots:
        dbt_test_project:
          file_format: delta
  - overrides: snapshot_strategy_timestamp
    dbt_project_yml: *file_format_delta
sequences:
  test_dbt_incremental: incremental
