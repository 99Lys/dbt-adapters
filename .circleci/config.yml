version: 2.1

jobs:
  unit:
    environment:
      DBT_INVOCATION_ENV: circle
    docker:
      - image: fishtownanalytics/test-container:9
    steps:
      - checkout
      - run: tox -e flake8,unit

  integration-spark-thrift:
    environment:
      DBT_INVOCATION_ENV: circle
    docker:
      - image: fishtownanalytics/test-container:9
      - image: godatadriven/spark:2
        environment:
          WAIT_FOR: localhost:5432
        command: >
          --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2
          --name Thrift JDBC/ODBC Server
          --conf spark.hadoop.javax.jdo.option.ConnectionURL=jdbc:postgresql://localhost/metastore
          --conf spark.hadoop.javax.jdo.option.ConnectionUserName=dbt
          --conf spark.hadoop.javax.jdo.option.ConnectionPassword=dbt
          --conf spark.hadoop.javax.jdo.option.ConnectionDriverName=org.postgresql.Driver

      - image: postgres:9.6.17-alpine
        environment:
          POSTGRES_USER: dbt
          POSTGRES_PASSWORD: dbt
          POSTGRES_DB: metastore

    steps:
      - checkout

      - run:
          name: Wait for Spark-Thrift
          command: dockerize -wait tcp://localhost:10000 -timeout 15m -wait-retry-interval 5s

      - run:
          name: Run integration tests
          command: tox -e integration-spark-thrift
          no_output_timeout: 1h
      - store_artifacts:
          path: ./logs

  integration-spark-databricks:
    environment:
      DBT_INVOCATION_ENV: circle
    docker:
      - image: fishtownanalytics/test-container:9
    steps:
      - checkout
      - run:
          name: Run integration tests
          command: tox -e integration-spark-databricks-http
          no_output_timeout: 1h
      - store_artifacts:
          path: ./logs

  # integration-spark-databricks-odbc:
  #   environment:
  #     DBT_INVOCATION_ENV: circle
  #   docker:
  #     - image: kwigley/spark-test-container:1
  #   steps:
  #     - checkout
  #     - run:
  #         name: Run integration tests
  #         command: ODBC_DRIVER=Simba tox -e integration-spark-databricks-odbc-cluster,integration-spark-databricks-odbc-sql-endpoint
  #         no_output_timeout: 1h
  #     - store_artifacts:
  #         path: ./logs

workflows:
  version: 2
  test-everything:
    jobs:
      - unit
      - integration-spark-thrift:
          requires:
            - unit
      - integration-spark-databricks:
          requires:
            - unit
      # - integration-spark-databricks-odbc:
      #     requires:
      #       - unit
